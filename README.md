# Data-Architecture

In this project, I used US Flight Delays dataset, which contains information about flight schedules and delays across multiple airlines and airports in the United States. I  performed an exploratory analysis of the dataset to gain insights into flight delays, identify patterns, and provide valuable information for airline companies and passengers.

___________________________________________________________________________________________________________________________________________________________________
![Flights (1)](https://github.com/Thamer0101/Data-Architecture/assets/127024138/9fba138c-82a0-46e2-b05f-49ffdc9542bd)


# 1- Loading dataset
### I loaded the dataset in oracle database tables by using SQL Developer IDE to storing the data

![oracle](https://github.com/Thamer0101/Data-Architecture/assets/127024138/23e6d680-68db-46d7-8bcb-7793fb17a021)
___________________________________________________________________________________________________________________________________________________________________
### sql query to checking the dataset loaded into the database successfully.


![sql](https://github.com/Thamer0101/Data-Architecture/assets/127024138/0f78475e-3166-47a5-a7df-3020c7754b5c)

___________________________________________________________________________________________________________________________________________________________________

## 2- Connecting to the oracle database using Spark application through jupyter IDE and importing the dataset.


![Spark UI3](https://github.com/Thamer0101/Data-Architecture/assets/127024138/973e4fb8-a4ee-495b-aab1-8407fa9ef3dd)

________________________________________________________________________________________________________________________________________

### Tools and technologies used in this project:
 This project makes use of various Big Data processing technologies including:
  - Oracle database,because oracle database has availability of having multiple databases, analytics tools, and machine learning environments.
  - Apache Spark, because of its ability to process massive amounts of data as well as the use of its unified analytics engine and convenient APIs
  - Pandas, due to its convenient dataframe manipulation functions
  - Matplotlib, to plot data and gain further insights





















